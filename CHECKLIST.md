# Quick Reference Checklist  
**Responsible Use of AI in Expert Reports on the Mental Functioning of Offenders**

---

## 1. Before Using AI
- [ ] Confirm the task is permitted (admin, transcription, literature review, quality checks, exploratory alternatives).  
- [ ] Ensure no identifying data will be sent to non-secure or public AI systems.  
- [ ] Check the tool is approved, secure, and listed in the Tool Register.  
- [ ] Frame prompts neutrally and clearly (no assumptions of guilt, blame, or diagnosis).  

---

## 2. During Use
- [ ] Keep a copy of each prompt and output for the audit trail.  
- [ ] De-identify all material provided to AI.  
- [ ] If generating alternatives or hypotheses, mark them as **tentative ideas only**.  
- [ ] Do not treat AI-generated text as final content or opinion.  

---

## 3. After Use
- [ ] Critically evaluate all outputs against evidence and professional judgment.  
- [ ] Independently verify facts, references, and quotations.  
- [ ] Review outputs for potential bias, stereotyping, or prejudicial language.  
- [ ] Edit the report manually; ensure final wording is the expert’s own.  

---

## 4. Finalising the Report
- [ ] Complete the **AI Disclosure Box** (tools used, tasks performed, safeguards).  
- [ ] Include the standard **Declaration on AI Use** in the report.  
- [ ] Attach the **AI Summary for Reports** if AI was used.  
- [ ] Confirm the final report expresses only the expert’s independent professional opinions.  

---

## 5. In Court
- [ ] Be prepared to explain what AI was used for, and what it was not.  
- [ ] Have the audit trail available if the Court requests it.  
- [ ] Reiterate that professional reasoning and conclusions are entirely your own.  

---

**Remember:**  
AI may support your work, but it cannot think, reason, or take responsibility.  
Only the expert provides opinions to the Court.  
